<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-01-25T14:44:29-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Olabode Anise</title><subtitle>Olabode Anise | My musings on security, data, and probably sports</subtitle><author><name>Olabode Anise</name></author><entry><title type="html">“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers</title><link href="http://localhost:4000/paper%20summary/usability-smartphone-pm/" rel="alternate" type="text/html" title="“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers" /><published>2020-01-25T00:00:00-05:00</published><updated>2020-01-25T00:00:00-05:00</updated><id>http://localhost:4000/paper%20summary/usability-smartphone-pm</id><content type="html" xml:base="http://localhost:4000/paper%20summary/usability-smartphone-pm/">&lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3319535.3354192&quot;&gt;“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers&lt;/a&gt; Seiler-Hwang et al., &lt;em&gt;Conference on Computers and Communication Security 2019&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Moving on from SOUPS, I took a look at the &lt;a href=&quot;https://sigsac.org/ccs/CCS2019/index.php/proceedings/&quot;&gt;proceedings&lt;/a&gt; from the Conference on Computers and Communication Security (CCS) and the first paper to catch my eye was the work by Seiler-Wang et al. The thing that stuck out about their work was that they studied a particular security tool that was popularized on desktops, in this case password managers (PM), and sought to understand the usability issues when used on a mobile device.&lt;/p&gt;

&lt;h2 id=&quot;setting-the-stage&quot;&gt;Setting the stage&lt;/h2&gt;
&lt;p&gt;For those who aren’t familiar with password managers, they’re digital wallets or vaults that assist in storing passwords or other secrets associated with different sites and services. In addition, to simply storing passwords they can help with password generation. While they can be immensely helpful, their usage is not widespread. According to two studies cited in the paper, password manager usage was seen to be at 17.6% [1] in 2016 and 16.7% [2] in 2018. However, mobile password usage is only at 6.8% [1]. The hypothesis is that usability issues are a factor and the authors seek to find out what those issues are.&lt;/p&gt;

&lt;h2 id=&quot;so-what-did-they-do&quot;&gt;So what did they do?&lt;/h2&gt;
&lt;p&gt;The authors conducted a usability study of four popular password managers: Dashlane, LastPass, Keeper and 1 Password. Each participant had to complete seven tasks ranging from installing and registering on the PM app to adjusting the security configurations of the PM.&lt;/p&gt;

&lt;p&gt;They evaluated their study using two tools: the standard System Usability Scale (SUS) and PACMAD (People at the Center of Mobile Application Development). Before reading this paper, I didn’t know that certain SUS scores were used to describe the general usability such as SUS scores with at least 70 means the product is &lt;em&gt;acceptable&lt;/em&gt;. You can see the other mappings in the figure below. PACMAD is an evaluation framework specific for mobile devices that focuses on seven attributes: effectiveness, efficiency, learnability, memorability, errors and cognitive load. They were able to evaluate these different attributes though the SUS, NASA Task Load Index, and a set of questionnaires.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/mobile-password-managers/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;They recruited participants through MTurk and had 20 participants complete the seven tasks for each of the four PMs resulting in 80 sets of responses. The user population that took part in the study was predominantly male, well educated, skewed young, and were mostly Android users. So the authors say that their results might not generalize well.&lt;/p&gt;

&lt;h2 id=&quot;certain-password-managers-are-better-than-others&quot;&gt;Certain password Managers are better than others&lt;/h2&gt;
&lt;p&gt;When looking at both the PACMAD Attributes and the SUS scores for each of the PMs, there were some interesting results. Let’s first start by looking at some of the PACMAD attributes.&lt;/p&gt;

&lt;h3 id=&quot;pacmad&quot;&gt;PACMAD&lt;/h3&gt;
&lt;p&gt;When evaluating the effectiveness of the four PMs, they all had a 90% success rate on average when combining the results from each of the tasks which is considered good. However, the task that had the lowest success rate was one which required the participant to download a native app for a service and login using a password stored in the PM. Participants were confused about the need to enable certain system-level permissions in order to enable auto-fill functionality. The authors hypothesize that this confusion is a result of a knowledge gap between certain groups of users.&lt;/p&gt;

&lt;p&gt;In contrast to effectiveness where each PM performed similarly, there were statistical differences found in the learnability of the different PMs.  Dashlane proved to have the highest learnability value (M = 75.6) with 1Password having the lowest score (51.3). The authors found that the learnability of Dashlane, LastPass and Keeper is similar with each being deemed “acceptable” according to the SUS. 1Password’s lower score was statistically different and fell in the “not acceptable” category according to the SUS.&lt;/p&gt;

&lt;h3 id=&quot;sus-scores&quot;&gt;SUS Scores&lt;/h3&gt;
&lt;p&gt;Dashlane received the highest average SUS score with a 76.5 while 1Password was the lowest receiving a 52.6. Based on the descriptions described earlier only Dashlane and Keeper have SUS scores that are deemed “acceptable”. Lastpass would be considered “marginal high” and 1Password would be in the “low marginal category.”  The figure below shows the distributions of the responses to the likert items that compose the SUS questionnaire.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/mobile-password-managers/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The authors also tried to understand the influence of demographics on the usability scores for each PM by using multiple linear regression and found that each model was not statistically significant.&lt;/p&gt;

&lt;h2 id=&quot;author-recommendations&quot;&gt;Author Recommendations&lt;/h2&gt;
&lt;p&gt;The authors’ recommendations to improve password managers to improve adoption centered around three things: User Guidance and Interaction, Integration and Security.&lt;/p&gt;

&lt;p&gt;On the &lt;strong&gt;user guidance front&lt;/strong&gt;, they detail how the PMs need to do three things:&lt;/p&gt;

&lt;p&gt;1) educate users on what PMs are, how they help with security, and the role of master passwords&lt;/p&gt;

&lt;p&gt;2) provide instructions on how to use basic functionalities&lt;/p&gt;

&lt;p&gt;3) better explain the different security settings&lt;/p&gt;

&lt;p&gt;The authors mention that this could be done with better help menus, tutorials, and instructions.&lt;/p&gt;

&lt;p&gt;In terms of &lt;strong&gt;integration&lt;/strong&gt;, the authors call out how their study found that not only was auto-fill the most useful feature, but also the most problematic. They recommend that mobile OSs offer better integration APIs and that native apps be more PM friendly.&lt;/p&gt;

&lt;p&gt;When it came to &lt;strong&gt;security&lt;/strong&gt;, the authors start by saying that better security leads to more user trust which can foster adoption. Specifically, they speak to the different policies surrounding the master password for each of the PMs with some accepting weaker password. They recommended having strong password policies for the master password and to provide feedback for users through password strength meeters and to offer additional levels of protection like MFA. Last, they talk about the trade-offs users make when adjusting security settings. They recommend that PMs provide additional feedback so that users are made aware of how the changes they’re making impact their security.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;I thought that work by Seiler-Hwange et. al, was particularly insightful and showed that there is still a lot of work that needs to be done to improve the usability of mobile password managers.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;.. a comparison of three biometrics (voice, face and gesture) against traditional passwords, concluded that the latter were the most usable with a SUS of 78, still a higher score than that of current popular PMs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My hope is that the entities developing them take this feedback and use it to develop more usable products because by doing so they will help reduce password re-use and improve the security of others.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;p&gt;[1]Nora Alkaldi and Karen Renaud. 2016. Why Do People Adopt, or Reject, Smart-phone Password Managers?. In 1st European Workshop on Usable Security (EuroSec2016). 1–14&lt;/p&gt;

&lt;p&gt;[2]Elizabeth Stobert and Robert Biddle. 2018. The password life cycle. ACM Transactions on Privacy and Security (TOPS) 21, 3 (2018), 13&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="security" /><summary type="html">“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers Seiler-Hwang et al., Conference on Computers and Communication Security 2019</summary></entry><entry><title type="html">Keepers of the Machines: Examining How System Administrators Manage Software Updates For Multiple Machines</title><link href="http://localhost:4000/paper%20summary/keepers/" rel="alternate" type="text/html" title="Keepers of the Machines: Examining How System Administrators Manage Software Updates For Multiple Machines" /><published>2020-01-17T00:00:00-05:00</published><updated>2020-01-17T00:00:00-05:00</updated><id>http://localhost:4000/paper%20summary/keepers</id><content type="html" xml:base="http://localhost:4000/paper%20summary/keepers/">&lt;p&gt;&lt;a href=&quot;https://www.usenix.org/system/files/soups2019-li.pdf&quot;&gt;Keepers of the Machines: Examining How System
Administrators Manage Software Updates&lt;/a&gt; Li et al., &lt;em&gt;SOUPS 2019&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Continuing through the SOUPS proceedings, I wanted to take some time to write about this paper by Frank Li, et. al. Their work focusing on the perspective of the administrator as it relates to managing software updates received the Distinguished Paper Award. I think what stood out about this paper is their focus on the admin. Most of the literature surrounding updating focuses on the end-user which is useful; however, admin who manages thousands of devices has to consider different things. In their work, they do an in-depth investigation of the process admins follow when updating the machines they manage.&lt;/p&gt;

&lt;h2 id=&quot;tell-me-about-the-data&quot;&gt;Tell me about the data&lt;/h2&gt;

&lt;p&gt;The data that they collected as part of this study came from two sources: a survey and semi-structured interviews. The survey that they administered had 41 questions and the participants were recruited through social media, blogs, and at the Large Installation System Administration Conference (LISA) conference. In total, they had 102 people take the survey. They coded the open-ended questions from the survey using open coding by two researchers. For the semi-structured interviews, they had 17 interview subjects which took part in interviews that ranged from 1 - 3 hours. Similar to the open-ended questions, two of the researchers coded the interview responses.&lt;/p&gt;

&lt;p&gt;The population that they interviewed was mostly male with 6/102 survey and 2/17 interview subjects being female. The survey respondents on average had a median of 11 years of experience, while the median for the interview subjects was 6 years. Another piece of demographic information that I found interesting was that almost half of the participants for both the survey (56/102) and the structured interviews (8/17) worked at organizations with more than 500 employees.&lt;/p&gt;

&lt;p&gt;After reading some of those demographic details, you are probably thinking that the respondents might not be representative of system admins in general and the authors would agree with you. In their paper, they call out that because of where and how they recruited participants their findings may not be representative of all admins.&lt;/p&gt;

&lt;h2 id=&quot;five-stages-of-updating&quot;&gt;Five Stages of Updating&lt;/h2&gt;

&lt;p&gt;From the data collected through the survey and the structured interviews, they found that the update process for administrators followed five stages:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Learning about updates from information sources&lt;/li&gt;
  &lt;li&gt;Deciding to update based on update characteristics&lt;/li&gt;
  &lt;li&gt;Preparing for update installation&lt;/li&gt;
  &lt;li&gt;Deploying the update&lt;/li&gt;
  &lt;li&gt;Handling post-deployment updates issues.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;where-do-you-get-your-info&quot;&gt;Where do you get your info&lt;/h3&gt;
&lt;p&gt;In both the survey and the interviews, they asked participants where they found out about updates. The participants provided a range of different sources which can be seen in Table 1 below.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/keeper/table1.png&quot; alt=&quot;table 2&quot; height=&quot;274px&quot; width=&quot;385px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The median survey respondent reported using a median of 5.0 different types of sources. The authors confirm what I thought while reading this paper – that admins could miss out on relevant information if they don’t follow a source in general or don’t diligently follow their usual sources. In addition, several of the sources named like blog posts and social media require the admin to take some action in order to receive any information.&lt;/p&gt;

&lt;h3 id=&quot;decisions-decisions&quot;&gt;Decisions, Decisions&lt;/h3&gt;

&lt;p&gt;After administrators find out about updates, they have to decide if they are going to actually deploy them. From the survey and interviews they found five general factors that affect whether or not they are going to apply an update:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update type&lt;/strong&gt;: The authors aksed the survey admins how regularly they installed security or non-security updates. They found that 97/102 admins regularly installed security updates while only 63/102 regularly installed non-security updates. The sentiment of regularly installing security updates was shared by the interview participants. The authors noted that while admins prioritize fixing security bugs/vulns many platforms bundle security patches along with along with other features. This means that they have to consider more than just improved security when applying updates.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update Severity&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update Relevance&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update Reliability&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Organization Factors&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;proper-preparation-prevents-poor-performance&quot;&gt;Proper Preparation Prevents Poor Performance&lt;/h3&gt;

&lt;p&gt;Once admins have decided to roll out an update, they made preparations that fell in three categories: making backups/snapshots, preparing machines in terms of changing configurations or dependencies and testing updates for bugs.&lt;/p&gt;

&lt;p&gt;In both the survey and semi-structured interviews, the authors asked participants about the problems that they’ve run into when trying to apply updates. The general sentiment was that it wasn’t an entirely easy process and that there was some risk even if it was small. The responses showed that some admins had worse experiences than others.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I stopped applying updates because it was becoming more
of a problem to apply them than not to. Production machines, they
don’t get updates” (P12).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I think it’s important to note that P12 probably has the best of intentions and desires when it comes to maintaining their organizations infrastructure, but they are jaded from their experience.&lt;/p&gt;

&lt;p&gt;When asked about the testing strategies that admins used for updates, most fell into one or two camps: staggered deployments or dedicated testing environments. Those that utilized staggered deployment had a few different approaches. One approach was applying updates based on priority levels with lower priority machines getting the updates first to uncover any potential issues. Another approach was to have a group of end users to help with update testing. For those that fell into the the dedicated testing, they used dedicated hardware or relied on a quality assurance (QA) team to to test updates.&lt;/p&gt;

&lt;p&gt;The authors note that both of these strategies have their downsides. When using the staggered deployment approach, higher priority machines or certain groups of users are left more susceptible to potential attackers. And to perform dedicated testing, admins must have access to the computing resources or employees which are dedicated to testing.&lt;/p&gt;

&lt;h3 id=&quot;ship-it&quot;&gt;Ship It&lt;/h3&gt;
&lt;p&gt;When asked how they deployed updates, the authors received a variety of answers from in-house scripts, automatic updates, to manual application. In addition, the methods that they used was dependent on the machine being updated. The majority of respondents used some type of third-party update manager such as Ansible or Chef to apply updates and   about half created custom scripts to deploy updates. While the respondents detailed the importance of automation when managing hundreds of machines, they also noted the effort that it takes to get that automation right.  Also, to no one’s surprise, manual updates were still common with 40/102 survey respondents and 4/17 interview subjects saying they conducted manual updates.&lt;/p&gt;

&lt;p&gt;The “when” to deploy is probably just as important as the how. Most of the interview subjects when asked when they would apply updates used either a predictable schedule such as a weekly patching program or to update during off-hours.&lt;/p&gt;

&lt;h3 id=&quot;it-worked-on-my-machine&quot;&gt;It worked on my machine.&lt;/h3&gt;
&lt;p&gt;As noted before applying updates can sometimes come with issues. The two most common approaches were to either just uninstall the update or rollback to a previous snapshot or backup. Both of these strategies aren’t great in that they leave the machines in their previous state which means that they’re potentially vulnerable if the update involved security patches. The two approaches really enforce the mindset that admins really want people to be able to get their jobs done. They are prioritizing functionality over security.&lt;/p&gt;

&lt;h2 id=&quot;lets-ask-the-boss&quot;&gt;Let’s ask the boss&lt;/h2&gt;

&lt;p&gt;The admins in this study had different organization policies or oversight when it came to applying updates. Some were given the autonomy to apply updates as they saw fit, some had to get buy-in from management before they could perform certain actions, and others had to comply with organizational policies or compliance requirements. Another unfortunate but not surprising finding by the authors was that several of the admins in this study commented on the not having budget to support admin operations surrounding updating such as software to deploy updates.&lt;/p&gt;

&lt;h2 id=&quot;so-what-should-change&quot;&gt;So what should change?&lt;/h2&gt;
&lt;p&gt;In the paper, the authors make several suggestions to ease the pain of managing software updates.&lt;/p&gt;

&lt;p&gt;When it came to finding out about updates, they suggest standardization and the consolidation update information into one place so that there’s a single source of truth. They also mention the possibility of outreach campaigns to promote updating and inform admins of vulnerabilities.&lt;/p&gt;

&lt;p&gt;To ease the decision making process of whether or not to install an update, the authors suggest splitting all-inclusive updates into updates of specific types. I think this is an interesting approach but one that could cause potentially more problems than good especially for platforms or software that is used by enterprises and common users. I personally would like to see some data surrounding the potential consistency in which users would install security only patches.&lt;/p&gt;

&lt;p&gt;To improve the deployment process, the authors encourage the usable security community to take a look a the common update tools to see how their interfaces could be improved. They also mentioned that dynamic software updating (DSU) which help the dreaded restart or downtime could help alleviate some of the problems associated with finding the right time to deploy. The authors relent that there are still a lot of unknowns surrounding the increased difficulty in developing patches that use DSU and the general usability of those systems.&lt;/p&gt;

&lt;p&gt;Last, the authors speak to the need for a cultural shift at organizations to understand the importance of quickly applying updates, especially those of the security variety. Moreover, they mention that without proper resources surrounding applying patches that security lapses like data breaches can occur. While they point out the importance of having organization support when it comes to applying patches, they note that getting to an ideal state is not straightforward.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;Frank Li and his co-authors point out that&lt;/p&gt;

&lt;p&gt;1) There are some similarities between the update process for admins and end-users but that admins have different considerations and operate on different scales&lt;/p&gt;

&lt;p&gt;2) There are distinct pain points throughout the admin’s process and there needs to be further research surrounding solutions to these pain points.&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="security" /><summary type="html">Keepers of the Machines: Examining How System Administrators Manage Software Updates Li et al., SOUPS 2019</summary></entry><entry><title type="html">Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries</title><link href="http://localhost:4000/paper%20summary/usability-smells/" rel="alternate" type="text/html" title="Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries" /><published>2020-01-09T00:00:00-05:00</published><updated>2020-01-09T00:00:00-05:00</updated><id>http://localhost:4000/paper%20summary/usability-smells</id><content type="html" xml:base="http://localhost:4000/paper%20summary/usability-smells/">&lt;p&gt;&lt;a href=&quot;https://www.usenix.org/system/files/soups2019-patnaik.pdf&quot;&gt;Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries&lt;/a&gt; Patnaik et al., &lt;em&gt;SOUPS 2019&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;While at SOUPS, this particular paper stood out because it related to some work that my colleagues and I were doing surrounding certificate chain validation. Cryptography is hard and using cryptographic APIs can be difficult too. This work uncovers usability smells associated with popular cryptography libraries by conducting a thematic analysis of 2,491 StackOverflow questions. A &lt;em&gt;usability&lt;/em&gt; smell is some sort of hint or indication that an interface may be difficult to use for its intended users. Usability smells are often thought of as it relates to graphical user interfaces (GUIs), but this way of thinking can be applied to APIs too.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Developers struggle with programming interfaces in the same way that users struggle with user interfaces.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;we-all-use-stack-overflow-right&quot;&gt;We all use Stack Overflow, right?&lt;/h2&gt;

&lt;p&gt;The researchers looked into seven popular cryptography libraries which are listed in the table below:&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table1.png&quot; alt=&quot;table 1&quot; height=&quot;660px&quot; width=&quot;344px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using the library names of the seven libraries as search terms, the researchers scraped Stack Overflow and found 2,491 questions. They did some post processing of the original corpus of questions to remove questions that didn’t relate to an issue in the library itself or where a developer wrongly attributed a question to a particular library. After this filtering, they were left with 2,316 questions to perform thematic analysis on.&lt;/p&gt;

&lt;p&gt;The researchers acknowledged that there were a couple of threats to the validity of their work: namely the staleness of questions and that the problem posed in the question was only encountered by a single developer and thus wasn’t a general problem with the library. To mitigate the first threat, they validated that the usability issued they identified was still present in the current version of the library. And to mitigate the seecond threat, they only selected questions that had a score of at least 1.&lt;/p&gt;

&lt;h2 id=&quot;the-issues&quot;&gt;The Issues&lt;/h2&gt;

&lt;p&gt;Through thematic analysis, the researchers found 16 usability issues that they grouped into 7 themes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/usability-smells/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Most of the issues are pretty intuitive and what you might be used to seeing on Stack Overflow. One of the issues that stood out to me was &lt;em&gt;borrowed mental models&lt;/em&gt; because I was wondering what it meant in this context. This particular issue arises when a develper tries to apply concepts from one library to another.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table2.png&quot; alt=&quot;table 2&quot; height=&quot;274px&quot; width=&quot;385px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The lionshare of the issues they found were with OpenSSL and  the two most prevalent types of issues were “What’s gone wrong here” (259) and “Build Issue” (362). This means that developers were having a lot of diffculty just setting up OpenSSL let alone actually using it.&lt;/p&gt;

&lt;p&gt;In contrast, LibSodium had the least amount of issues with a total of 26 relevant issues. Maybe that is to be expected from library whose claims to be a “modern, portable, easy to use crypto library.”&lt;/p&gt;

&lt;h2 id=&quot;usability-smells&quot;&gt;Usability Smells&lt;/h2&gt;
&lt;p&gt;After identifiying the themes associated with the issues in the Stack Overflow questions, the researchers attempted to map them onto the 10 usability principles  by Green and Smith. They did not map the &lt;em&gt;lack of knowledge&lt;/em&gt; or &lt;em&gt;passing the buck&lt;/em&gt; issues since these are associated with specific developer behaviors and aren’t associated with the problems with the library itself. Through the mapping they found four usability smells which can be found in the table below:&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table3.png&quot; alt=&quot;table 3&quot; height=&quot;918px&quot; width=&quot;550px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Needs a super sleuth&lt;/strong&gt;: this smell means usually means it is hard to find the information you need to accomplish a particular task or that it is diffcult to understand how to do it with the library.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Confusion regins&lt;/strong&gt;: this usability smells comes out before any code is written. The developer is unsusre if this is right library to use or how to use the library.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Needs a post-mortem&lt;/strong&gt;: unlike &lt;em&gt;confusions regins&lt;/em&gt; the issues associated with this smells happen after writing code. Whether it is because an update has broken their code or they are generally struggling to use the library, something went wrong.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Doesn’t play well with others&lt;/strong&gt;. For a library to be easy-to-use, a developer must be able to actually use it.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-bad-are-the-smells&quot;&gt;How bad are the smells?&lt;/h2&gt;

&lt;p&gt;For the three libraries that that had the most issues OpenSSL, Bouncy Castle, and PyCrypto, the researchers added what they call a &lt;em&gt;Whiffiness factor&lt;/em&gt;. It is a weighted average of the percentage frequency of the issues associated with each whiff.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table4.png&quot; alt=&quot;table 3&quot; height=&quot;812px&quot; width=&quot;564px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of the three libraries analyzed, OpenSSL came out to be the “stinkiest” but in reality it’s not much different than the other libraries. There are areas that it shines and areas that need some improvement.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Libraries will perhaps always be a bit smelly given
the challenges of catering for the requirements of a wide and
diverse set of developers and applications; but by integrating
usability principles we can at least make them less so.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Olabode Anise</name></author><category term="security" /><summary type="html">Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries Patnaik et al., SOUPS 2019</summary></entry><entry><title type="html">Recommitment to Usable Security</title><link href="http://localhost:4000/general/recommitment/" rel="alternate" type="text/html" title="Recommitment to Usable Security" /><published>2020-01-06T00:00:00-05:00</published><updated>2020-01-06T00:00:00-05:00</updated><id>http://localhost:4000/general/recommitment</id><content type="html" xml:base="http://localhost:4000/general/recommitment/">&lt;p&gt;We’re a few days into 2020, and like a lot of people I’ve tried to set my intentions/goals for the year. One of those intentions is to recommit myself to studying and learning about the field of Usable Security.&lt;/p&gt;

&lt;p&gt;In a past life, I was a PhD student at the University of Florida studying Usable Security as part of the Human-Centered Computing Program. For a few reasons that I won’t get into, I left the program after my first year to work at Duo Security. Looking back, I’m so glad that I made that decision. It has afforded me the opportunity to work with great people and to work on some really cool projects. Unfortunately, most of my work as a Data Scientist doesn’t afford me the opportunity to work in the Usable Security space. To pile on, my pursuit of a master’s degree didn’t allow me to really scratch that itch or really do much of anything outside of work. But with that degree completed and with a bit of free time back, I want to invest that time in learning and growing in an area I’m passionate about.&lt;/p&gt;

&lt;p&gt;So my goal for 2020 is to read more usable security papers and to write some paper summaries as way of solidifying my understanding of what I read as well as improve my technical writing. I’m hoping to write at least one paper summary a week in the style of &lt;a href=&quot;https://blog.acolyer.org/&quot;&gt;the morning paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I like to look for tools to hold myself accountable and now that I’ve written this post and put it on the Internet I guess I’ve found one for this goal :).&lt;/p&gt;</content><author><name>Olabode Anise</name></author><summary type="html">We’re a few days into 2020, and like a lot of people I’ve tried to set my intentions/goals for the year. One of those intentions is to recommit myself to studying and learning about the field of Usable Security.</summary></entry></feed>